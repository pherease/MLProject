{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb01a081",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-15 17:18:55.335821: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1752592735.355832   49228 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1752592735.361561   49228 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1752592735.376532   49228 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752592735.376553   49228 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752592735.376556   49228 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752592735.376557   49228 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-15 17:18:55.381046: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No existing logs directory found at: ./logs\n"
     ]
    }
   ],
   "source": [
    "import os, random, numpy as np\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import utils  # your local utils.py\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "num_classes = 9\n",
    "\n",
    "# Set up reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)\n",
    "\n",
    "\n",
    "# Use mixed precision and GPU memory management like tiny.py\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "matplotlib.use(\"Agg\")\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "\n",
    "logs_dir = \"./logs\"\n",
    "\n",
    "# Check if logs directory exists\n",
    "if os.path.exists(logs_dir):\n",
    "    print(f\"Clearing logs directory: {logs_dir}\")\n",
    "    shutil.rmtree(logs_dir)  # delete the folder and all its contents\n",
    "else:\n",
    "    print(f\"No existing logs directory found at: {logs_dir}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "894299d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN {np.int64(0): 276, np.int64(1): 246, np.int64(2): 252, np.int64(3): 474, np.int64(4): 297, np.int64(5): 300, np.int64(6): 552, np.int64(7): 190, np.int64(8): 261}  (total: 2848)\n",
      "VAL   {np.int64(0): 92, np.int64(1): 82, np.int64(2): 84, np.int64(3): 158, np.int64(4): 99, np.int64(5): 100, np.int64(6): 184, np.int64(7): 64, np.int64(8): 87}  (total: 950)\n",
      "TEST  {np.int64(0): 93, np.int64(1): 83, np.int64(2): 84, np.int64(3): 158, np.int64(4): 99, np.int64(5): 100, np.int64(6): 185, np.int64(7): 64, np.int64(8): 88}  (total: 954)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1752592738.509488   49228 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 84 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 128\n",
    "BATCH = 2\n",
    "\n",
    "TRAIN_CSV = \"./split_data/train.csv\"\n",
    "VAL_CSV = \"./split_data/val.csv\"\n",
    "TEST_CSV = \"./split_data/test.csv\"\n",
    "\n",
    "train_paths, train_labels, train_label_encoder = utils.load_paths_and_labels(TRAIN_CSV)\n",
    "val_paths, val_labels, val_label_encoder = utils.load_paths_and_labels(VAL_CSV)\n",
    "test_paths, test_labels, test_label_encoder = utils.load_paths_and_labels(TEST_CSV)\n",
    "\n",
    "# Optional: SAMPLE tiny dataset for FAST testing\n",
    "# train_paths, train_labels = train_paths[:20], train_labels[:20]\n",
    "# val_paths, val_labels = val_paths[:10], val_labels[:10]\n",
    "\n",
    "# Show class distributions\n",
    "utils.show_dataset_class_distribution(\"TRAIN\", train_labels)\n",
    "utils.show_dataset_class_distribution(\"VAL  \", val_labels)\n",
    "utils.show_dataset_class_distribution(\"TEST \", test_labels)\n",
    "\n",
    "# Build datasets\n",
    "augment_layer = utils.make_augment()\n",
    "train_ds = utils.make_dataset(train_paths, train_labels, BATCH, shuffle=True, autotune=True)\n",
    "train_ds = train_ds.map(lambda imgs, labs: (augment_layer(imgs, training=True), labs), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_ds = utils.make_dataset(val_paths, val_labels, BATCH, shuffle=False, autotune=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21ee0c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cw_vals = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_labels),\n",
    "    y=train_labels\n",
    ")\n",
    "class_w = dict(enumerate(cw_vals))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a254df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3)))\n",
    "\n",
    "    # Convolutional layers\n",
    "    for i in range(hp.Int(\"conv_blocks\", 3, 5, default=4)):\n",
    "        filters = hp.Choice(f\"filters_{i}\", values=[32, 64, 128, 256], default=64)\n",
    "        model.add(layers.Conv2D(filters, (3,3), padding=\"same\"))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.LeakyReLU(alpha=0.1))\n",
    "        model.add(layers.MaxPooling2D(2,2))\n",
    "\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "    # Dense layers\n",
    "    dense_units = hp.Int(\"dense_units\", min_value=64, max_value=256, step=32, default=128)\n",
    "    model.add(layers.Dense(dense_units))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    \n",
    "    dropout_rate = hp.Float(\"dropout\", min_value=0.2, max_value=0.5, step=0.05, default=0.3)\n",
    "    model.add(layers.Dropout(dropout_rate))\n",
    "\n",
    "    # Final layer\n",
    "    model.add(layers.Dense(num_classes, activation='softmax', dtype='float32'))\n",
    "\n",
    "    # Compile\n",
    "    lr = hp.Float(\"learning_rate\", min_value=1e-4, max_value=1e-2, sampling=\"log\", default=1e-3)\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da3c74d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.Hyperband(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=5,   # FAST: reduce for tests\n",
    "    factor=3,\n",
    "    directory='logs',\n",
    "    project_name='RealWaste_quick_test'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4e660ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppose your validation loss is around 0.5\n",
    "initial_val_loss = 0.5\n",
    "min_delta_percent = 0.1\n",
    "min_delta_absolute = min_delta_percent * initial_val_loss  # = 0.05\n",
    "\n",
    "early_stop_cb = EarlyStopping(\n",
    "    monitor='val_loss',    \n",
    "    patience=5,            # stop after 5 epochs with no sufficient improvement\n",
    "    min_delta=min_delta_absolute,\n",
    "    mode='min',            \n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc8fcad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 Complete [00h 00m 06s]\n",
      "\n",
      "Best val_accuracy So Far: None\n",
      "Total elapsed time: 00h 00m 11s\n",
      "\n",
      "Search: Running Trial #3\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "3                 |4                 |conv_blocks\n",
      "64                |64                |filters_0\n",
      "32                |256               |filters_1\n",
      "32                |64                |filters_2\n",
      "256               |32                |filters_3\n",
      "160               |224               |dense_units\n",
      "0.25              |0.4               |dropout\n",
      "0.0098403         |0.0010144         |learning_rate\n",
      "128               |None              |filters_4\n",
      "2                 |2                 |tuner/epochs\n",
      "0                 |0                 |tuner/initial_epoch\n",
      "1                 |1                 |tuner/bracket\n",
      "0                 |0                 |tuner/round\n",
      "\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-15 17:19:16.315525: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 16.00MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-07-15 17:19:16.327798: W tensorflow/core/framework/op_kernel.cc:1857] OP_REQUIRES failed at xla_ops.cc:591 : UNKNOWN: Failed to determine best cudnn convolution algorithm for:\n",
      "%cudnn-conv-bias-activation.9 = (f32[2,64,128,128]{3,2,1,0}, u8[0]{0}) custom-call(f32[2,3,128,128]{3,2,1,0} %bitcast.7018, f32[64,3,3,3]{3,2,1,0} %bitcast.6568, f32[64]{0} %bitcast.7653), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1/convolution\" source_file=\"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "\n",
      "Original error: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 16777472 bytes. [tf-allocator-allocation-error='']\n",
      "\n",
      "To ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py\", line 274, in _try_run_and_update_trial\n",
      "    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n",
      "  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py\", line 239, in _run_and_update_trial\n",
      "    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/keras_tuner/src/tuners/hyperband.py\", line 427, in run_trial\n",
      "    return super().run_trial(trial, *fit_args, **fit_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/keras_tuner/src/engine/tuner.py\", line 314, in run_trial\n",
      "    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/keras_tuner/src/engine/tuner.py\", line 233, in _build_and_fit_model\n",
      "    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/keras_tuner/src/engine/hypermodel.py\", line 149, in fit\n",
      "    return model.fit(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/tensorflow/python/eager/execute.py\", line 59, in quick_execute\n",
      "    except TypeError as e:\n",
      "tensorflow.python.framework.errors_impl.UnknownError: Graph execution error:\n",
      "\n",
      "Detected at node StatefulPartitionedCall defined at (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "\n",
      "  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "\n",
      "  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "\n",
      "  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "\n",
      "  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "\n",
      "  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/asyncio/base_events.py\", line 645, in run_forever\n",
      "\n",
      "  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/asyncio/base_events.py\", line 1999, in _run_once\n",
      "\n",
      "  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "\n",
      "  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "\n",
      "  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "\n",
      "  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "\n",
      "  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "\n",
      "  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "\n",
      "  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "\n",
      "  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "\n",
      "  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3098, in run_cell\n",
      "\n",
      "  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3153, in _run_cell\n",
      "\n",
      "  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "\n",
      "  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3362, in run_cell_async\n",
      "\n",
      "  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3607, in run_ast_nodes\n",
      "\n",
      "  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3667, in run_code\n",
      "\n",
      "  File \"/tmp/ipykernel_49228/1247914572.py\", line 3, in <module>\n",
      "\n",
      "  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py\", line 234, in search\n",
      "\n",
      "  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py\", line 274, in _try_run_and_update_trial\n",
      "\n",
      "  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py\", line 239, in _run_and_update_trial\n",
      "\n",
      "  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/keras_tuner/src/tuners/hyperband.py\", line 427, in run_trial\n",
      "\n",
      "  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/keras_tuner/src/engine/tuner.py\", line 314, in run_trial\n",
      "\n",
      "  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/keras_tuner/src/engine/tuner.py\", line 233, in _build_and_fit_model\n",
      "\n",
      "  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/keras_tuner/src/engine/hypermodel.py\", line 149, in fit\n",
      "\n",
      "  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n",
      "\n",
      "  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 377, in fit\n",
      "\n",
      "  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 220, in function\n",
      "\n",
      "  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 133, in multi_step_on_iterator\n",
      "\n",
      "Failed to determine best cudnn convolution algorithm for:\n",
      "%cudnn-conv-bias-activation.9 = (f32[2,64,128,128]{3,2,1,0}, u8[0]{0}) custom-call(f32[2,3,128,128]{3,2,1,0} %bitcast.7018, f32[64,3,3,3]{3,2,1,0} %bitcast.6568, f32[64]{0} %bitcast.7653), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1/convolution\" source_file=\"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "\n",
      "Original error: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 16777472 bytes. [tf-allocator-allocation-error='']\n",
      "\n",
      "To ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n",
      "\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_multi_step_on_iterator_14847]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Number of consecutive failures exceeded the limit of 3.\nTraceback (most recent call last):\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py\", line 274, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py\", line 239, in _run_and_update_trial\n    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/keras_tuner/src/tuners/hyperband.py\", line 427, in run_trial\n    return super().run_trial(trial, *fit_args, **fit_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/keras_tuner/src/engine/tuner.py\", line 314, in run_trial\n    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/keras_tuner/src/engine/tuner.py\", line 233, in _build_and_fit_model\n    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/keras_tuner/src/engine/hypermodel.py\", line 149, in fit\n    return model.fit(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/tensorflow/python/eager/execute.py\", line 59, in quick_execute\n    except TypeError as e:\ntensorflow.python.framework.errors_impl.UnknownError: Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/asyncio/base_events.py\", line 645, in run_forever\n\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/asyncio/base_events.py\", line 1999, in _run_once\n\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/asyncio/events.py\", line 88, in _run\n\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3098, in run_cell\n\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3153, in _run_cell\n\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3362, in run_cell_async\n\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3607, in run_ast_nodes\n\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3667, in run_code\n\n  File \"/tmp/ipykernel_49228/1247914572.py\", line 3, in <module>\n\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py\", line 234, in search\n\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py\", line 274, in _try_run_and_update_trial\n\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py\", line 239, in _run_and_update_trial\n\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/keras_tuner/src/tuners/hyperband.py\", line 427, in run_trial\n\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/keras_tuner/src/engine/tuner.py\", line 314, in run_trial\n\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/keras_tuner/src/engine/tuner.py\", line 233, in _build_and_fit_model\n\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/keras_tuner/src/engine/hypermodel.py\", line 149, in fit\n\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 377, in fit\n\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 220, in function\n\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 133, in multi_step_on_iterator\n\nFailed to determine best cudnn convolution algorithm for:\n%cudnn-conv-bias-activation.9 = (f32[2,64,128,128]{3,2,1,0}, u8[0]{0}) custom-call(f32[2,3,128,128]{3,2,1,0} %bitcast.7018, f32[64,3,3,3]{3,2,1,0} %bitcast.6568, f32[64]{0} %bitcast.7653), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1/convolution\" source_file=\"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n\nOriginal error: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 16777472 bytes. [tf-allocator-allocation-error='']\n\nTo ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_multi_step_on_iterator_14847]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m tensorboard_cb = tf.keras.callbacks.TensorBoard(log_dir=\u001b[33m'\u001b[39m\u001b[33mlogs/tensorboard\u001b[39m\u001b[33m'\u001b[39m, histogram_freq=\u001b[32m1\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mtuner\u001b[49m\u001b[43m.\u001b[49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclass_w\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mearly_stop_cb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m                \u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtensorboard_cb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m                \u001b[49m\u001b[43mutils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcheckpoint_cb\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m                \u001b[49m\u001b[43mutils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcsv_logger_cb\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m            \u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/MLP/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py:235\u001b[39m, in \u001b[36mBaseTuner.search\u001b[39m\u001b[34m(self, *fit_args, **fit_kwargs)\u001b[39m\n\u001b[32m    233\u001b[39m     \u001b[38;5;28mself\u001b[39m.on_trial_begin(trial)\n\u001b[32m    234\u001b[39m     \u001b[38;5;28mself\u001b[39m._try_run_and_update_trial(trial, *fit_args, **fit_kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mon_trial_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[38;5;28mself\u001b[39m.on_search_end()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/MLP/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py:339\u001b[39m, in \u001b[36mBaseTuner.on_trial_end\u001b[39m\u001b[34m(self, trial)\u001b[39m\n\u001b[32m    333\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mon_trial_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial):\n\u001b[32m    334\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Called at the end of a trial.\u001b[39;00m\n\u001b[32m    335\u001b[39m \n\u001b[32m    336\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m    337\u001b[39m \u001b[33;03m        trial: A `Trial` instance.\u001b[39;00m\n\u001b[32m    338\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m339\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moracle\u001b[49m\u001b[43m.\u001b[49m\u001b[43mend_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    340\u001b[39m     \u001b[38;5;28mself\u001b[39m.save()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/MLP/lib/python3.12/site-packages/keras_tuner/src/engine/oracle.py:108\u001b[39m, in \u001b[36msynchronized.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    106\u001b[39m     LOCKS[oracle].acquire()\n\u001b[32m    107\u001b[39m     THREADS[oracle] = thread_name\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m ret_val = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m need_acquire:\n\u001b[32m    110\u001b[39m     THREADS[oracle] = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/MLP/lib/python3.12/site-packages/keras_tuner/src/engine/oracle.py:588\u001b[39m, in \u001b[36mOracle.end_trial\u001b[39m\u001b[34m(self, trial)\u001b[39m\n\u001b[32m    586\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retry(trial):\n\u001b[32m    587\u001b[39m     \u001b[38;5;28mself\u001b[39m.end_order.append(trial.trial_id)\n\u001b[32m--> \u001b[39m\u001b[32m588\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_check_consecutive_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    590\u001b[39m \u001b[38;5;28mself\u001b[39m._save_trial(trial)\n\u001b[32m    591\u001b[39m \u001b[38;5;28mself\u001b[39m.save()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/MLP/lib/python3.12/site-packages/keras_tuner/src/engine/oracle.py:545\u001b[39m, in \u001b[36mOracle._check_consecutive_failures\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    543\u001b[39m     consecutive_failures = \u001b[32m0\u001b[39m\n\u001b[32m    544\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m consecutive_failures == \u001b[38;5;28mself\u001b[39m.max_consecutive_failed_trials:\n\u001b[32m--> \u001b[39m\u001b[32m545\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    546\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNumber of consecutive failures exceeded the limit \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    547\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mof \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.max_consecutive_failed_trials\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    548\u001b[39m         + (trial.message \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    549\u001b[39m     )\n",
      "\u001b[31mRuntimeError\u001b[39m: Number of consecutive failures exceeded the limit of 3.\nTraceback (most recent call last):\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py\", line 274, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py\", line 239, in _run_and_update_trial\n    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/keras_tuner/src/tuners/hyperband.py\", line 427, in run_trial\n    return super().run_trial(trial, *fit_args, **fit_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/keras_tuner/src/engine/tuner.py\", line 314, in run_trial\n    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/keras_tuner/src/engine/tuner.py\", line 233, in _build_and_fit_model\n    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/keras_tuner/src/engine/hypermodel.py\", line 149, in fit\n    return model.fit(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/tensorflow/python/eager/execute.py\", line 59, in quick_execute\n    except TypeError as e:\ntensorflow.python.framework.errors_impl.UnknownError: Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/asyncio/base_events.py\", line 645, in run_forever\n\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/asyncio/base_events.py\", line 1999, in _run_once\n\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/asyncio/events.py\", line 88, in _run\n\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3098, in run_cell\n\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3153, in _run_cell\n\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3362, in run_cell_async\n\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3607, in run_ast_nodes\n\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3667, in run_code\n\n  File \"/tmp/ipykernel_49228/1247914572.py\", line 3, in <module>\n\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py\", line 234, in search\n\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py\", line 274, in _try_run_and_update_trial\n\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py\", line 239, in _run_and_update_trial\n\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/keras_tuner/src/tuners/hyperband.py\", line 427, in run_trial\n\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/keras_tuner/src/engine/tuner.py\", line 314, in run_trial\n\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/keras_tuner/src/engine/tuner.py\", line 233, in _build_and_fit_model\n\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/keras_tuner/src/engine/hypermodel.py\", line 149, in fit\n\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 377, in fit\n\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 220, in function\n\n  File \"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 133, in multi_step_on_iterator\n\nFailed to determine best cudnn convolution algorithm for:\n%cudnn-conv-bias-activation.9 = (f32[2,64,128,128]{3,2,1,0}, u8[0]{0}) custom-call(f32[2,3,128,128]{3,2,1,0} %bitcast.7018, f32[64,3,3,3]{3,2,1,0} %bitcast.6568, f32[64]{0} %bitcast.7653), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1/convolution\" source_file=\"/home/jarus/miniconda3/envs/MLP/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n\nOriginal error: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 16777472 bytes. [tf-allocator-allocation-error='']\n\nTo ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_multi_step_on_iterator_14847]\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(log_dir='logs/tensorboard', histogram_freq=1)\n",
    "\n",
    "tuner.search(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    class_weight=class_w,\n",
    "    epochs=50,\n",
    "    callbacks=[early_stop_cb,\n",
    "                reduce_lr,\n",
    "                tensorboard_cb,\n",
    "                utils.checkpoint_cb(),\n",
    "                utils.csv_logger_cb()\n",
    "            ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3ece17",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hp = tuner.get_best_hyperparameters(1)[0]\n",
    "print(\"Best hyperparameters found:\")\n",
    "print(f\"Conv Blocks: {best_hp.get('conv_blocks')}\")\n",
    "for i in range(best_hp.get('conv_blocks')):\n",
    "    print(f\"Filters_{i}: {best_hp.get(f'filters_{i}')}\")\n",
    "print(f\"Dense units: {best_hp.get('dense_units')}\")\n",
    "print(f\"Dropout: {best_hp.get('dropout')}\")\n",
    "print(f\"Learning rate: {best_hp.get('learning_rate')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db768540",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = tuner.hypermodel.build(best_hp)\n",
    "history = best_model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=50,\n",
    "    callbacks=[early_stop_cb, reduce_lr]\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
